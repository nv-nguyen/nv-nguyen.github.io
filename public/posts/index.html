<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  

  <title>
    
      Posts
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/" />
  
  
  
  <link rel="stylesheet" href="/css/main.af4ea5289c8ec9e0f0023142ce5200378e27d5ada0a48b688af4b4f2480ead78d68c8f2dc3d65146596e452aafaf77a05b1445e14e58c4bfb0f72cff4a372472.css" integrity="sha512-r06lKJyOyeDwAjFCzlIAN44n1a2gpItoivS08kgOrXjWjI8tw9ZRRlluRSqvr3egWxRF4U5YxL&#43;w9yz/Sjckcg==" />
  
</head>
<body a="auto">
        <main class="page-content" aria-label="Content">
            <div class="w">
<a href="/">..</a>


<h1>Posts</h1>





    
	<table style="border:none" cellspacing="0" cellpadding="0"><tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/bop24.jpg style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2025-06-11
			</span>
            		<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2024/">BOP Challenge 2024 on Model-free, Model-based Detection, and Pose Estimation of Unseen Rigid Objects</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, Stephen Tyree, Andrew Guo, Médéric Fourmy, Anas Gouda, Taeyeop Lee, Sungphill Moon, Hyeontae Son, Lukas Ranftl, Jonathan Tremblay, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Stan Birchfield, Jiri Matas, Yann Labbé, Martin Sundermeyer, Tomáš Hodaň</p>
<p>CVPRW 2025 <!-- raw HTML omitted -->(Best Paper Award)<!-- raw HTML omitted --></p>
<p>We introduce a new model-free variant of all tasks, define a new 6D object detection task, and introduce three new publicly available datasets.</p>
<p><a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2024/">[project page]</a>  <a href="https://arxiv.org/pdf/2504.02812">[arXiv]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/gotrack.jpg style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2025-06-11
			</span>
            		<a href="">GoTrack: Generic 6DoF Object Pose Refinement and Tracking</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, <a href="https://www.cforster.ch">Christian Forster</a>, <a href="https://www.linkedin.com/in/sindi-shkodrani/">Sindi Shkodrani</a>, <a href="https://btekin.github.io">Bugra Tekin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://www.linkedin.com/in/cem-keskin-23692a15">Cem Keskin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://thodan.github.io/">Tomáš Hodaň</a></p>
<p>CVPRW 2025</p>
<p>We introduce GoTrack, an efficient and accurate CAD-based method for 6DoF pose refinement and tracking of unseen objects. Given a CAD model of an object, an RGB image with known intrinsics that shows the object in an unknown pose, and an initial object pose, Gotrack refines the object pose such as the 2D projection of the model aligns closely with the object’s appearance in the image.</p>
<p><a href="https://arxiv.org/abs/2506.07155">[arXiv]</a>  <a href="https://github.com/facebookresearch/gotrack">[code]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/bop23.png style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2024-06-17
			</span>
            		<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2023/">BOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects</a>
			<br>
    			<p>Tomas Hodan, Martin Sundermeyer, Yann Labbé, <strong>Van Nguyen Nguyen</strong>, Gu Wang, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Jiri Matas</p>
<p>CVPRW 2024</p>
<p>The report of BOP challenge 2023 on state-of-the-art methods for seen and unseen object pose estimation.</p>
<p><a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2023/">[project page]</a>   <a href="https://arxiv.org/pdf/2403.09799.pdf">[arXiv]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/gigaPose.png style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2024-06-17
			</span>
            		<a href="https://nv-nguyen.github.io/gigapose">GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2024</p>
<p>A &ldquo;hybrid&rdquo; template-patch correspondence approach that is fast, robust, and more accurate to estimate 6D pose of novel objects in RGB images. GigaPose predicts 6D object pose from a single 2D-to-2D correspondence.</p>
<p><a href="https://nv-nguyen.github.io/gigapose">[project page]</a>   <a href="http://arxiv.org/abs/2311.14155">[arXiv]</a>   <a href="https://github.com/nv-nguyen/gigapose">[code]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/nope.gif style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2024-06-17
			</span>
            		<a href="https://nv-nguyen.github.io/nope">NOPE: Novel Object Pose Estimation from a Single Image</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://ponimatkin.github.io/">Georgy Ponimatkin</a>, <a href="https://yinlinhu.github.io/">Yinlin Hu</a>, <a href="http://imagine.enpc.fr/~marletr/">Renaud Marlet</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2024</p>
<p>A method that can estimate relative pose of unseen objects given only a single reference image. It also predicts 3D pose distribution which can be used to address pose ambiguities due to symmetries.</p>
<p><a href="https://nv-nguyen.github.io/nope">[project page]</a>   <a href="https://arxiv.org/abs/2303.13612">[arXiv]</a>   <a href="https://nv-nguyen.github.io/nope">[code]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/osv5m.png style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2024-06-17
			</span>
            		<a href="https://osv5m.github.io/">OpenStreetView-5M: The Many Roads to Global Visual Geolocation</a>
			<br>
    			<p>Guillaume Astruc, Nicolas Dufour, Ioannis Siglidis, Constantin Aronssohn, Nacim Bouia, Stephanie Fu, Romain Loiseau, <strong>Van Nguyen Nguyen</strong>, Charles Raude, Elliot Vincent, Lintao Xu, Hongyu Zhou, Loic Landrieu</p>
<p>CVPR 2024</p>
<p>A new benchmark for visual geolocation (~Geoguessr).</p>
<p><a href="https://osv5m.github.io/">[project page]</a>   <a href="https://arxiv.org/abs/2404.18873">[arXiv]</a>   <a href="https://github.com/gastruc/osv5m">[code]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/cnos_ycb_pred.gif style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2023-10-01
			</span>
            		<a href="https://nv-nguyen.github.io/cnos/">CNOS: A Strong Baseline for CAD-based Novel Object Segmentation</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://ponimatkin.github.io/">Georgy Ponimatkin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://thodan.github.io/">Tomáš Hodaň</a></p>
<p>ICCVW 2023 <!-- raw HTML omitted -->(Best Method Award for 2D detection of unseen objects)<!-- raw HTML omitted --></p>
<p>A method that can segment novel objects for a given RGB image from only their CAD models. Based on Segmenting Anything, DINOv2, CNOS is a strong baseline for Task 5 and 6 in the BOP challenge 2023.</p>
<p><a href="https://nv-nguyen.github.io/cnos/">[project page]</a>   <a href="https://arxiv.org/abs/2307.11067">[arXiv]</a>   <a href="https://github.com/nv-nguyen/cnos">[code]</a></p>

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/pizza.png style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2022-12-01
			</span>
            		<a href="https://arxiv.org/pdf/2209.07589">PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6DoF Tracking</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong><!-- raw HTML omitted -->+<!-- raw HTML omitted -->, <a href="https://dulucas.github.io/Homepage/">Yuming Du</a><!-- raw HTML omitted -->+<!-- raw HTML omitted -->, <a href="https://youngxiao13.github.io/">Yang Xiao</a>, <a href="https://michaelramamonjisoa.github.io/">Michaël Ramamonjisoa</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>3DV <!-- raw HTML omitted -->(Oral)<!-- raw HTML omitted --></p>
<p>A method for tracking the 6D motion of objects in RGB video sequences when neither training images nor even the 3D geometry of the objects is available.</p>
<!-- raw HTML omitted -->

			</td>	
		</tr>	
        <tr>	
			<td style="width:25%; border:none; vertical-align:middle;">	
    			<img src=/images/template-pose.png style="width:100%" />
			</td>	
			<td style="width:75%; border:none; vertical-align:middle; padding:20px">	
            		<span>2022-06-01
			</span>
            		<a href="https://nv-nguyen.github.io/template-pose">Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions</a>
			<br>
    			<p><strong>Van Nguyen Nguyen</strong>, <a href="https://yinlinhu.github.io/">Yinlin Hu</a>, <a href="https://youngxiao13.github.io/">Yang Xiao</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2022</p>
<p>A method that can recognize objects and estimate their 3D pose in color images even under partial occlusions. Our method requires neither a training phase on these objects nor real images depicting them, only their CAD models.</p>
<p><a href="https://nv-nguyen.github.io/template-pose">[project page]</a>   <a href="https://arxiv.org/abs/2203.17234">[arXiv]</a>   <a href="https://github.com/nv-nguyen/template-pose">[code]</a></p>

			</td>	
		</tr>	
        
	</table>





            </div>
        </main>
    </body></html>
