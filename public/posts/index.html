<!DOCTYPE html>
<html lang=""><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  

  <title>
    
      Posts
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.4/css/academicons.min.css" />
  
  
  
  <link rel="stylesheet" href="/css/main.433d83f74a27edc339f83048b85eb45476f4fbedf08fe58fe4fc516a726fad21ceadf229d96e830b9a1c1d16db27bc9c0a4bcd4f544ff8f2936e154d11ce1420.css" integrity="sha512-Qz2D90on7cM5&#43;DBIuF60VHb0&#43;&#43;3wj&#43;WP5PxRanJvrSHOrfIp2W6DC5ocHRbbJ7ycCkvNT1RP&#43;PKTbhVNEc4UIA==" />
  
</head>
<body a="light">
        <span id="theme-toggle" class="theme-toggle" aria-label="Toggle dark/light mode"></span>
        <main class="page-content" aria-label="Content">
            <div class="w">
<a href="/">..</a>


<h1>Posts</h1>





    <div class="pub-card">
		<div class="pub-img">
			<img src=/images/cif.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://adreamwu.github.io/Consistent-Instance-Field/">CIF: Consistent Instance Field for Dynamic Scene Understanding</a>
			<br>
			<p><a href="https://adreamwu.github.io/">Junyi Wu</a>, <strong>Van Nguyen Nguyen</strong>, <a href="https://planche.me/">Benjamin Planche</a>, <a href="https://scholar.google.com/citations?user=FdXm3_AAAAAJ">Jiachen Tao</a>, <a href="https://scholar.google.com/citations?user=5jErMqMAAAAJ">Changchang Sun</a>, <a href="https://scholar.google.com/citations?user=AFOCPkUAAAAJ">Zhongpai Gao</a>, <a href="https://scholar.google.com/citations?user=VxYsD0MAAAAJ">Zhenghao Zhao</a>, <a href="https://anwesachoudhuri.github.io/">Anwesa Choudhuri</a>, <a href="https://scholar.google.com/citations?user=0gellDsAAAAJ">Gengyu Zhang</a>, <a href="https://scholar.google.com/citations?user=TsgMRsUAAAAJ">Meng Zheng</a>, <a href="https://scholar.google.com/citations?user=7sFMIKoAAAAJ">Feiran Wang</a>, <a href="https://scholar.google.com/citations?user=PISXgwMAAAAJ">Terrence Chen</a>, <a href="https://tomyan555.github.io/">Yan Yan</a>, <a href="https://scholar.google.com/citations?user=1JDFQBUAAAAJ">Ziyan Wu</a></p>
<p>CVPR 2026</p>
<p>A continuous probabilistic spatio-temporal representation for dynamic scene understanding that disentangles visibility from persistent object identity. Our approach employs instance-embedded deformable 3D Gaussians that encode both radiance and semantic information, enabling novel-view panoptic segmentation and open-vocabulary 4D querying tasks.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2512.14126">[arXiv]</a>
  <a href="https://adreamwu.github.io/Consistent-Instance-Field/">[project page]</a>
</span>

		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/medgrpo_v2.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://yuhaosu.github.io/MedGRPO/">MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding</a>
			<br>
			<p><a href="https://scholar.google.com/citations?user=Q-ARFPIAAAAJ">Yuhao Su</a>, <a href="https://anwesachoudhuri.github.io/">Anwesa Choudhuri</a>, <a href="https://scholar.google.com/citations?user=AFOCPkUAAAAJ">Zhongpai Gao</a>, <a href="https://planche.me/">Benjamin Planche</a>, <strong>Van Nguyen Nguyen</strong>, <a href="https://scholar.google.com/citations?user=TsgMRsUAAAAJ">Meng Zheng</a>, <a href="https://scholar.google.com/citations?user=8vNMmGMAAAAJ">Yuhan Shen</a>, <a href="https://scholar.google.com/citations?user=7CJ-vBQAAAAJ">Arun Innanje</a>, <a href="https://scholar.google.com/citations?user=PISXgwMAAAAJ">Terrence Chen</a>, <a href="https://www.ccs.neu.edu/home/eelhami/">Ehsan Elhamifar</a>, <a href="https://scholar.google.com/citations?user=1JDFQBUAAAAJ">Ziyan Wu</a></p>
<p>CVPR 2026</p>
<p>We introduce MedVidBench, a large-scale benchmark of 531K video-instruction pairs across 8 medical sources, and MedGRPO, an RL framework with cross-dataset reward normalization and a medical LLM judge for balanced multi-dataset training. Fine-tuning Qwen2.5-VL-7B on MedVidBench substantially outperforms GPT-4.1 and Gemini-2.5-Flash, while MedGRPO further improves grounding and captioning tasks.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2512.06581">[arXiv]</a>
  <a href="https://yuhaosu.github.io/MedGRPO/">[project page]</a>
</span>

		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/ubs.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://rongliu-leo.github.io/universal-beta-splatting/">Universal Beta Splatting</a>
			<br>
			<p><a href="https://rongliu-leo.github.io/">Rong Liu</a>, <a href="https://scholar.google.com/citations?user=AFOCPkUAAAAJ">Zhongpai Gao</a>, <a href="https://planche.me/">Benjamin Planche</a>, <a href="https://scholar.google.com/citations?user=ii_J7K4AAAAJ">Meida Chen</a>, <strong>Van Nguyen Nguyen</strong>, <a href="https://scholar.google.com/citations?user=TsgMRsUAAAAJ">Meng Zheng</a>, <a href="https://anwesachoudhuri.github.io/">Anwesa Choudhuri</a>, <a href="https://scholar.google.com/citations?user=PISXgwMAAAAJ">Terrence Chen</a>, <a href="https://yuewang.xyz/">Yue Wang</a>, <a href="https://ict.usc.edu/about-us/leadership/research-leadership/andrew-feng/">Andrew Feng</a>, <a href="https://scholar.google.com/citations?user=1JDFQBUAAAAJ">Ziyan Wu</a></p>
<p>ICLR 2026</p>
<p>A unified framework that generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for explicit radiance field rendering. Beta kernels naturally decompose scene properties into interpretable components (surface vs. texture, diffuse vs. specular, static vs. dynamic) without explicit supervision.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2510.03312">[arXiv]</a>
  <a href="https://rongliu-leo.github.io/universal-beta-splatting/">[project page]</a>
  <a href="https://github.com/RongLiu-Leo/universal-beta-splatting">[code]</a>
  <a href="https://github.com/RongLiu-Leo/universal-beta-splatting/stargazers">
    <img src="https://img.shields.io/github/stars/RongLiu-Leo/universal-beta-splatting?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/RongLiu-Leo/universal-beta-splatting/network/members">
    <img src="https://img.shields.io/github/forks/RongLiu-Leo/universal-beta-splatting?style=social" alt="GitHub forks">
  </a>
</span>

		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/bop24.jpg style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2024/">BOP Challenge 2024 on Model-free, Model-based Detection, and Pose Estimation of Unseen Rigid Objects</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, Stephen Tyree, Andrew Guo, Médéric Fourmy, Anas Gouda, Taeyeop Lee, Sungphill Moon, Hyeontae Son, Lukas Ranftl, Jonathan Tremblay, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Stan Birchfield, Jiri Matas, Yann Labbé, Martin Sundermeyer, Tomáš Hodaň</p>
<p>CVPRW 2025 <span class="red">(Best Paper Award)</span></p>
<p>The report of BOP Challenge 2024 on model-based and model-free 2D/6D object detection on BOP-Classic and new BOP-H3 datasets (HOT3D, HOPEv2, HANDAL).</p>
<p><a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2024/">project page</a>  <a href="https://arxiv.org/pdf/2504.02812">arXiv</a></p>

		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/gotrack.jpg style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="">GoTrack: Generic 6DoF Object Pose Refinement and Tracking</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, <a href="https://www.cforster.ch">Christian Forster</a>, <a href="https://www.linkedin.com/in/sindi-shkodrani/">Sindi Shkodrani</a>, <a href="https://btekin.github.io">Bugra Tekin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://www.linkedin.com/in/cem-keskin-23692a15">Cem Keskin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://thodan.github.io/">Tomáš Hodaň</a></p>
<p>CVPRW 2025</p>
<p>An efficient and accurate CAD-based method for 6DoF pose refinement and tracking of unseen objects. Given a CAD model of an object, an RGB image with known intrinsics that shows the object in an unknown pose, and an initial object pose, Gotrack refines the object pose such as the 2D projection of the model aligns closely with the object’s appearance in the image.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2506.07155">[arXiv]</a>
  <a href="https://github.com/facebookresearch/gotrack">[code]</a>
  <a href="https://github.com/facebookresearch/gotrack/stargazers">
    <img src="https://img.shields.io/github/stars/facebookresearch/gotrack?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/facebookresearch/gotrack/network/members">
    <img src="https://img.shields.io/github/forks/facebookresearch/gotrack?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/bop23.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2023/">BOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects</a>
			<br>
			<p>Tomas Hodan, Martin Sundermeyer, Yann Labbé, <strong>Van Nguyen Nguyen</strong>, Gu Wang, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Jiri Matas</p>
<p>CVPRW 2024</p>
<p>The report of BOP Challenge 2023 on state-of-the-art methods for seen and unseen object pose estimation.</p>
<p><a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2023/">project page</a>   <a href="https://arxiv.org/pdf/2403.09799.pdf">arXiv</a></p>

		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/gigaPose.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://nv-nguyen.github.io/gigapose">GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2024</p>
<p>A &ldquo;hybrid&rdquo; template-patch correspondence approach that is fast, robust, and more accurate to estimate 6D pose of novel objects in RGB images. GigaPose predicts 6D object pose from a single 2D-to-2D correspondence.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2311.14155">[arXiv]</a>
  <a href="https://github.com/nv-nguyen/gigapose">[code]</a>
  <a href="https://github.com/nv-nguyen/gigapose/stargazers">
    <img src="https://img.shields.io/github/stars/nv-nguyen/gigapose?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/nv-nguyen/gigapose/network/members">
    <img src="https://img.shields.io/github/forks/nv-nguyen/gigapose?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/nope.gif style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://nv-nguyen.github.io/nope">NOPE: Novel Object Pose Estimation from a Single Image</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://ponimatkin.github.io/">Georgy Ponimatkin</a>, <a href="https://yinlinhu.github.io/">Yinlin Hu</a>, <a href="http://imagine.enpc.fr/~marletr/">Renaud Marlet</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2024</p>
<p>A method that can estimate relative pose of unseen objects given only a single reference image. It also predicts 3D pose distribution which can be used to address pose ambiguities due to symmetries.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2303.13612">[arXiv]</a>
  <a href="https://github.com/nv-nguyen/nope">[code]</a>
  <a href="https://github.com/nv-nguyen/nope/stargazers">
    <img src="https://img.shields.io/github/stars/nv-nguyen/nope?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/nv-nguyen/nope/network/members">
    <img src="https://img.shields.io/github/forks/nv-nguyen/nope?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/osv5m.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://osv5m.github.io/">OpenStreetView-5M: The Many Roads to Global Visual Geolocation</a>
			<br>
			<p>Guillaume Astruc, Nicolas Dufour, Ioannis Siglidis, Constantin Aronssohn, Nacim Bouia, Stephanie Fu, Romain Loiseau, <strong>Van Nguyen Nguyen</strong>, Charles Raude, Elliot Vincent, Lintao Xu, Hongyu Zhou, Loic Landrieu</p>
<p>CVPR 2024</p>
<p>A new benchmark for visual geolocation (~Geoguessr).</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2404.18873">[arXiv]</a>
  <a href="https://github.com/gastruc/osv5m">[code]</a>
  <a href="https://github.com/gastruc/osv5m/stargazers">
    <img src="https://img.shields.io/github/stars/gastruc/osv5m?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/gastruc/osv5m/network/members">
    <img src="https://img.shields.io/github/forks/gastruc/osv5m?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/cnos_ycb_pred.gif style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://nv-nguyen.github.io/cnos/">CNOS: A Strong Baseline for CAD-based Novel Object Segmentation</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a>, <a href="https://ponimatkin.github.io/">Georgy Ponimatkin</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a>, <a href="https://thodan.github.io/">Tomáš Hodaň</a></p>
<p>ICCVW 2023 <span class="red">(Best Method Award for 2D detection of unseen objects)</span></p>
<p>A method that can segment novel objects for a given RGB image from only their CAD models. Based on Segmenting Anything, DINOv2, CNOS is a strong baseline for Task 5 and 6 in the BOP challenge 2023.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2307.11067">[arXiv]</a>
  <a href="https://github.com/nv-nguyen/cnos">[code]</a>
  <a href="https://github.com/nv-nguyen/cnos/stargazers">
    <img src="https://img.shields.io/github/stars/nv-nguyen/cnos?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/nv-nguyen/cnos/network/members">
    <img src="https://img.shields.io/github/forks/nv-nguyen/cnos?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/pizza.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://arxiv.org/pdf/2209.07589">PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6DoF Tracking</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong><sup>+</sup>, <a href="https://dulucas.github.io/Homepage/">Yuming Du</a><sup>+</sup>, <a href="https://youngxiao13.github.io/">Yang Xiao</a>, <a href="https://michaelramamonjisoa.github.io/">Michaël Ramamonjisoa</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>3DV <span class="red">(Oral)</span></p>
<p>A method for tracking the 6D motion of objects in RGB video sequences when neither training images nor even the 3D geometry of the objects is available.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2209.07589">[arXiv]</a>
  <a href="https://github.com/nv-nguyen/pizza">[code]</a>
  <a href="https://github.com/nv-nguyen/pizza/stargazers">
    <img src="https://img.shields.io/github/stars/nv-nguyen/pizza?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/nv-nguyen/pizza/network/members">
    <img src="https://img.shields.io/github/forks/nv-nguyen/pizza?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        <div class="pub-card">
		<div class="pub-img">
			<img src=/images/template-pose.png style="width:100%" />
		</div>
		<div class="pub-info">
			<a href="https://nv-nguyen.github.io/template-pose">Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions</a>
			<br>
			<p><strong>Van Nguyen Nguyen</strong>, <a href="https://yinlinhu.github.io/">Yinlin Hu</a>, <a href="https://youngxiao13.github.io/">Yang Xiao</a>, <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>, <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a></p>
<p>CVPR 2022</p>
<p>A method that can recognize objects and estimate their 3D pose in color images even under partial occlusions. Our method requires neither a training phase on these objects nor real images depicting them, only their CAD models.</p>
<span class="links-line">
  <a href="https://arxiv.org/pdf/2203.17234">[arXiv]</a>
  <a href="https://github.com/nv-nguyen/template-pose">[code]</a>
  <a href="https://github.com/nv-nguyen/pizza/stargazers">
    <img src="https://img.shields.io/github/stars/nv-nguyen/template-pose?style=social" alt="GitHub stars">
  </a>
  <a href="https://github.com/nv-nguyen/template-pose/network/members">
    <img src="https://img.shields.io/github/forks/nv-nguyen/template-pose?style=social" alt="GitHub forks">
  </a>
</span>
		</div>
	</div>
        





            </div>
        </main>
        <script>
        (function() {
          var btn = document.getElementById('theme-toggle');
          var body = document.body;

          function getEffectiveTheme() {
            var a = body.getAttribute('a');
            if (a === 'dark' || a === 'light') return a;
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
          }

          function updateButton() {
            btn.textContent = getEffectiveTheme() === 'dark' ? '[light]' : '[dark]';
          }

          var saved = localStorage.getItem('theme');
          if (saved) body.setAttribute('a', saved);

          updateButton();

          btn.addEventListener('click', function() {
            var next = getEffectiveTheme() === 'dark' ? 'light' : 'dark';
            body.setAttribute('a', next);
            localStorage.setItem('theme', next);
            updateButton();
          });
        })();
        </script>
    </body></html>
